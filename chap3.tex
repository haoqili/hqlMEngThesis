%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{User Interface}

Here, we describe the user interface of the CameraDP and CameraCL apps. CameraDP and CameraCL assign phones into different regions based on their GPS locations. A region's LEADER collectively saves the newest photos for all the phones in the region, which implies: a) a new photo is saved on its phone's region, not the phone itself and b) a phone can only request the newest photo of a region, not from another individual phone or an earlier picture (it's easy to change the code to save more than one photo). 

From the user's point of view, CameraDP and CameraCL are identical. Both apps allow users to share photos among themselves using their Android phones.  The users can take new photos on their phones, by pressing the \textquotedblleft Take Photo" button and request to see the latest photos taken by other phones by pressing the \textquotedblleft Get X Photo" button where \textquotedblleft X" corresponds to the desired region number. We preconfigure 6 regions in the experiments with numbers 0 - 5. The \textquotedblleft Take Photo" button press triggers a TAKE request in CameraDP and the \textquotedblleft Get X Photo" button press triggers a GET request. These are the only two requests we allow.  Figure \ref{fig:uiphone-png}, taken from an experiment, shows CameraDP in yellow to the left and CameraCL in blue to the right. The only visible difference between these two apps besides their background color is that the CameraCL phones do not have the DIPLOMA information: state, ID, and leader.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=14cm]{uiphone.png}
\caption{The UI of CameraDP (left, yellow) and CameraCL (right, blue). This figure is taken from Experiment 6, where phones are placed on chairs. The top left square is an active preview from the phone camera, currently black due to obstruction by the chair.The latest photo taken or retrieved is shown on the top right rectangle. DIPLOMA information (absent in CameraCL) and the phone Region is displayed below the photo. Below the TAKE and GET buttons, the numerical buttons are used to manually change regions for indoor experiments. Next, a scrollable log message list is displayed to aid debugging. The fractions that follow ``t" and ``g" are successful requests over requests made for TAKE and GET, respectively, followed by their percentages of success. For outdoor experiments, ``w", ``h", and ``gps" display the region width, amount of hysteresis, and the region calculated from GPS (currently broken). These three values are meaningless for indoor experiments where users manually set regions. The ``*mn", ``*md", ``*n" show the mean, median, and the newest request latency in milliseconds. The last row set region width and hysteresis for outdoor experiments. For CameraDP, the orange icon indicating an active ad-hoc Wifi from the Barnacle app is displayed on the top left corner.}
\label{fig:uiphone-png}
\end{center}
\end{figure}

The rest of the UI are add-ons to help with the debugging process. Log messages are displayed in the middle. Success rates of TAKEs and GETs are displayed on the bottom of the screen, along with request latency information. The textfield is for setting a new region width. While changing the region width on one phone, all the other phones involved must have the region width changed as well to keep the region assignments consistent among all phones. 

The last button is a switch for hysteresis, allowing the user to pick different percentages of the region width to be applied to the hysteresis buffer region. If hysteresis is set, the region of the phone cannot be changed inside the hysteresis region, which corresponds to the few meters (based on the hysteresis percentage chosen) around the boundaries of the regions. Hysteresis was set to 0 after Experiment 2 due to its complications discussed in the previous chapter.

For all experiments after the first, after a user presses a TAKE request or GET request button the UI is frozen until the request is finished, preventing double clicking a button and resending a request. A double button click and request may cause the camera to be in an inconsistent state, causing the app to crash. There are two levels of disabling the UI, a ProgressDialog and a boolean flag. The ProgressDialog darkens the screen and shows a popup of a spinner, literally freezing the entire UI. It is dismissed when the request is finished. The boolean flag, 'areButtonsEnabled', is independent from the ProgressDialog to serve as another line of defense agains double clicks. Whenever the user clicks on a request button, the global 'areButtonsEnabled' flag is checked and the request only proceeds if the flag is true. As soon as it's determined that the request can proceed, the flag is immediately set to false so that any subsequent button clicks cannot proceed. The flag is set back to true at the completion of the request. The completion of the request could either be receiving the request reply or reaching a timeout. This boolean flag is analogous to a lock.

The camera and photo taking interface is provided by a custom CameraSurfaceView class. At the beginning of development, we used the built-in camera image capturing intent, a much simpler way of retrieving pictures. When a user wants to take a picture, the phone is redirected to the Android camera snapshot mode, filling the entire phone screen with a photo preview. After the user takes a picture and is satisfied the phone goes back to the CameraDP or CameraCL app, with the picture shown at the top of the app. However this simple solution only worked on the Nexus S phones. On Galaxy Notes, this error
\begin{verbatim}
Cannot open socket
Address already in use
\end{verbatim}
comes up and causes the app to crash. Somehow, the built-in camera interface works differently on Galaxy Notes by leaving the original CameraDP or CameraCL app in a different state when the phone switches to the snapshot mode. After switching to CameraSurfaceView, we no longer see the error, because the camera preview and photo taking process is directly integrated into the CameraDP or CameraCL app itself, so we never have to leave the app to take a picture. It provided a friendlier UI because the users can see a preview of the picture at any point, directly in the CameraDP or CameraCL app. Since CameraSurfaceView works on both types of phones, we used this solution for both.

Every picture generated from a TAKE is both downsampled ({\it BitmapFactory.options.inSampleSize = 12}) and compressed in the JPEG format with a compression quality of 10. The {\it inSampleSize}  of 12 means that the original image is sampled at every 12th pixel in either dimension, thus reducing the original number of photo bytes by a factor of 144. The JPEG compression quality can be an integer from 0 to 100, where 0 generates the smallest picture and 100 generates the picture with the best quality. Without compression, a picture is over 1,000,000 bytes. After these two steps, only 2000 - 6000 bytes are left of the picture, which is sent through the ad-hoc Wifi to its local LEADER to be saved. Due to the high loss rate on Wifi, packets containing larger photos are more prone to be dropped. We decided to compress the photos greatly after finding, in Micro-Experiment 1 (Chapter 6), that 64-byte {\it pinging} packets could be delivered successfully over a longer distance than larger photo packets. Even though CameraCL does not use Wifi, the images are resized in the same way for fair bandwidth and latency comparisons.